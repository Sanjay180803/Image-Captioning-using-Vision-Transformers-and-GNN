{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8319352,"sourceType":"datasetVersion","datasetId":4941476},{"sourceId":8321976,"sourceType":"datasetVersion","datasetId":4943449},{"sourceId":8338680,"sourceType":"datasetVersion","datasetId":4952390}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow\nimport keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint('tensorflow: %s' % tensorflow.__version__)\nprint('keras: %s' % keras.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T18:40:01.174708Z","iopub.execute_input":"2024-05-05T18:40:01.175072Z","iopub.status.idle":"2024-05-05T18:40:13.009549Z","shell.execute_reply.started":"2024-05-05T18:40:01.175044Z","shell.execute_reply":"2024-05-05T18:40:13.008676Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from numpy import array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, concatenate\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:40:22.920624Z","iopub.execute_input":"2024-05-05T18:40:22.921232Z","iopub.status.idle":"2024-05-05T18:40:22.937352Z","shell.execute_reply.started":"2024-05-05T18:40:22.9212Z","shell.execute_reply":"2024-05-05T18:40:22.936396Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from os import listdir\nfrom pickle import dump\nfrom keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.models import Model\n\ndef extract_features(address,filenames):\n    model = VGG19()\n    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n    print(model.summary())\n    features = dict()\n    for name in filenames:\n        filename = address + name\n        image = load_img(filename, target_size = (224,224))\n        image = img_to_array(image)\n        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n        image = preprocess_input(image)\n        feature = model.predict(image, verbose = 0)\n        image_id = name.split('.')[0]\n        features[image_id] = feature\n        #print('>%s' % name)\n    return features\n    \ndirectory = '/kaggle/input/imageclef/train/train'","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:40:28.504386Z","iopub.execute_input":"2024-05-05T18:40:28.504996Z","iopub.status.idle":"2024-05-05T18:40:28.514779Z","shell.execute_reply.started":"2024-05-05T18:40:28.504966Z","shell.execute_reply":"2024-05-05T18:40:28.513816Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_dataset = listdir(directory)\ndirectory1='/kaggle/input/imageclef/test_images/test'\ntrain_data = image_dataset\ntest_data = listdir(directory1)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:40:35.137662Z","iopub.execute_input":"2024-05-05T18:40:35.13851Z","iopub.status.idle":"2024-05-05T18:40:36.37222Z","shell.execute_reply.started":"2024-05-05T18:40:35.138476Z","shell.execute_reply":"2024-05-05T18:40:36.371375Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"The number of jpg flies in Flicker8k: {}\".format(len(image_dataset)))\nprint(\"The number of jpg flies in Train data: {}\".format(len(train_data)))\nprint(\"The number of jpg flies in Test data: {}\".format(len(test_data)))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:40:39.577496Z","iopub.execute_input":"2024-05-05T18:40:39.577855Z","iopub.status.idle":"2024-05-05T18:40:39.583616Z","shell.execute_reply.started":"2024-05-05T18:40:39.577827Z","shell.execute_reply":"2024-05-05T18:40:39.58255Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check for GPU availability\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    print(\"GPU is available. TensorFlow will use GPU:\", gpus)\n    try:\n        # Set GPU memory growth to prevent TensorFlow from allocating all memory at once\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\nelse:\n    print(\"GPU not available. Using CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:40:43.196767Z","iopub.execute_input":"2024-05-05T18:40:43.197172Z","iopub.status.idle":"2024-05-05T18:40:43.402442Z","shell.execute_reply.started":"2024-05-05T18:40:43.197131Z","shell.execute_reply":"2024-05-05T18:40:43.400565Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_features =  extract_features(directory +'/' , train_data)\ntest_features = extract_features(directory1 + '/', test_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T09:01:36.216586Z","iopub.execute_input":"2024-05-05T09:01:36.217314Z","iopub.status.idle":"2024-05-05T10:52:17.773709Z","shell.execute_reply.started":"2024-05-05T09:01:36.217279Z","shell.execute_reply":"2024-05-05T10:52:17.772892Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/working/features.pkl', 'wb') as f:\n   pickle.dump(train_features, f)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T10:55:16.439471Z","iopub.execute_input":"2024-05-05T10:55:16.440139Z","iopub.status.idle":"2024-05-05T10:55:19.709138Z","shell.execute_reply.started":"2024-05-05T10:55:16.440104Z","shell.execute_reply":"2024-05-05T10:55:19.708147Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport csv\n\ndf = pd.read_csv('/kaggle/input/imageclef/train_captions.csv')\n\nwith open('/kaggle/input/imageclef/train_captions.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n    next(csv_reader)\n    \n    with open('/kaggle/working/captions_1.txt', 'w') as txt_file:\n        for row in csv_reader:\n            img_id = row[0]\n            caption = row[1]\n    \n            txt_file.write(f\"{img_id} {caption}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:41:11.862405Z","iopub.execute_input":"2024-05-05T18:41:11.863028Z","iopub.status.idle":"2024-05-05T18:41:12.471129Z","shell.execute_reply.started":"2024-05-05T18:41:11.862997Z","shell.execute_reply":"2024-05-05T18:41:12.470139Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\nimport numpy as np\nunique_images = np.unique(df.ID.values)\nprint(\"The number of unique image names : {}\".format(len(unique_images)))\nprint(\"The distribution of the number of captions for each image:\")\nCounter(Counter(df.ID.values).values())","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:41:28.564729Z","iopub.execute_input":"2024-05-05T18:41:28.565351Z","iopub.status.idle":"2024-05-05T18:41:28.650382Z","shell.execute_reply.started":"2024-05-05T18:41:28.565319Z","shell.execute_reply":"2024-05-05T18:41:28.649457Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nnum_pic = 5\ntarget_size = (224, 224, 3)\n\ncount = 1\nfig = plt.figure(figsize=(10, 20))\nfor img in unique_images[7669:7669+num_pic]:\n    filename = directory+'/'+img+\".jpg\"\n    captions = list(df[\"Caption\"].loc[df[\"ID\"] == img].values)\n    image_load = load_img(filename, target_size=target_size)    \n    ax = fig.add_subplot(num_pic, 2, count, xticks=[], yticks=[])\n    ax.imshow(image_load)\n    count += 1\n    ax = fig.add_subplot(num_pic, 2, count)\n    plt.axis('off')\n    ax.plot()\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, len(captions))\n    for i, caption in enumerate(captions):\n        ax.text(0, i, caption, fontsize=20)\n    count += 1\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:41:33.614228Z","iopub.execute_input":"2024-05-05T18:41:33.615065Z","iopub.status.idle":"2024-05-05T18:41:34.556582Z","shell.execute_reply.started":"2024-05-05T18:41:33.615024Z","shell.execute_reply":"2024-05-05T18:41:34.555718Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def df_word(df_txt):\n    vocabulary = []\n    for i in range(len(df_txt)):\n        temp=df_txt.iloc[i,1]\n        vocabulary.extend(temp.split())\n    print('Vocabulary Size: %d' % len(set(vocabulary)))\n    ct = Counter(vocabulary)\n    dfword = pd.DataFrame({\"word\":list(ct.keys()),\"count\":list(ct.values())})\n    dfword = dfword.sort_values(\"count\",ascending=False)\n    dfword = dfword.reset_index()[[\"word\",\"count\"]]\n    return(dfword)\ndfword = df_word(df)\ndfword.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:41:40.892345Z","iopub.execute_input":"2024-05-05T18:41:40.892718Z","iopub.status.idle":"2024-05-05T18:41:43.619846Z","shell.execute_reply.started":"2024-05-05T18:41:40.892689Z","shell.execute_reply":"2024-05-05T18:41:43.618933Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"topn = 50\n\ndef plthist(dfsub, title=\"The top 50 most frequently appearing words\"):\n    plt.figure(figsize=(20,3))\n    plt.bar(dfsub.index,dfsub[\"count\"])\n    plt.yticks(fontsize=20)\n    plt.xticks(dfsub.index,dfsub[\"word\"],rotation=90,fontsize=20)\n    plt.title(title,fontsize=20)\n    plt.show()\n\nplthist(dfword.iloc[:topn,:],\n        title=\"Top 50 most frequently appearing words\")\nplthist(dfword.iloc[-topn:,:],\n        title=\"Least 50 appearing words\")","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:41:55.57368Z","iopub.execute_input":"2024-05-05T18:41:55.57405Z","iopub.status.idle":"2024-05-05T18:41:56.968494Z","shell.execute_reply.started":"2024-05-05T18:41:55.574021Z","shell.execute_reply":"2024-05-05T18:41:56.967595Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import string\nimport re\n\ndef load_doc(filename):\n    file = open(filename, 'r')\n    text = file.read()\n    file.close()\n    return text\n\ndef load_descriptions(doc):\n    mapping = dict()\n    for line in doc.split('\\n'):\n        tokens = line.split()\n        if len(line) < 2:\n            continue\n        image_id, image_desc = tokens[0], tokens[1:]\n        image_id = image_id.split('.')[0]\n        image_desc = ' '.join(image_desc)\n        if image_id not in mapping:\n            mapping[image_id] = list()\n        mapping[image_id].append(image_desc)\n    return mapping\n\ndef clean_descriptions(descriptions):\n    table = str.maketrans('','',string.punctuation)\n    for key, desc_list in descriptions.items():\n        for i in range(len(desc_list)):\n            desc = desc_list[i]\n            desc = desc.split()\n            desc = [word.lower() for word in desc]\n            desc = [re.sub(r'[^\\w\\s]', '', w) for w in desc]\n            desc = [word for word in desc if len(word) > 1]\n            desc = [word for word in desc if word.isalpha()]\n            desc_list[i] = ' '.join(desc)\n\ndef to_vocabulary(descriptions):\n    all_desc = set()\n    for key in descriptions.keys():\n        [all_desc.update(d.split()) for d in descriptions[key]]\n    return all_desc\n\ndef save_descriptions(descriptions, filename):\n    lines = list()\n    for key, desc_list in descriptions.items():\n        for desc in desc_list:\n            lines.append(key + ' ' + desc)\n    data = '\\n'.join(lines)\n    \n    filename.write(data)\n    filename.close()\n\nfilename = '/kaggle/working/captions_1.txt'\ndoc = load_doc(filename)\ndescriptions = load_descriptions(doc)\nprint('Loaded: %d' % len(descriptions))\nclean_descriptions(descriptions)\nvoc = to_vocabulary(descriptions)\nprint('Vocabulary size: %d' % len(voc))\nwith open('/kaggle/working/descriptions_1.txt', 'w') as f:\n      save_descriptions(descriptions, f)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:42:06.954662Z","iopub.execute_input":"2024-05-05T18:42:06.955029Z","iopub.status.idle":"2024-05-05T18:42:10.58574Z","shell.execute_reply.started":"2024-05-05T18:42:06.955002Z","shell.execute_reply":"2024-05-05T18:42:10.58478Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def modify_descriptions(img_names, img_descs):\n    desc_dict = dict()\n    for key, desc in img_descs.items():\n        if key in img_names:\n            modified_desc = list()\n            for i in range(len(desc)):\n                modified_desc.append('startseq ' + desc[i] + ' endseq')\n            desc_dict[key] = modified_desc\n            print(modified_desc)\n    return desc_dict\n\ntrain_image_names = [i.split('.')[0] for i in train_data]\ntest_image_names = [i.split('.')[0] for i in test_data]\n\ntrain_descriptions = modify_descriptions(train_image_names, descriptions)    \ntest_descriptions = modify_descriptions(test_image_names, descriptions)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T18:24:29.778742Z","iopub.execute_input":"2024-05-05T18:24:29.779148Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.utils import to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\n\n\ndef to_lines(descriptions):\n    all_desc = list()\n    for key in descriptions.keys():\n        [all_desc.append(d) for d in descriptions[key]]\n    return all_desc\n  \ndef create_tokenizer(desc):\n    lines = to_lines(desc)\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(lines)\n    return tokenizer\n\ntokenizer = create_tokenizer(train_descriptions)\nvocab_size = len(tokenizer.word_index) + 1\nprint('Vocabulary Size: %d' % vocab_size)\n\ndef max_length_function(desc):\n    lines = to_lines(desc)\n    return max(len(d.split()) for d in lines)\n\ndef create_sequences(tokenizer, max_length, desc_list, photo):\n    X1, X2, y = [], [], []\n    for desc in desc_list:\n        seq = tokenizer.texts_to_sequences([desc])[0]\n        for i in range(1, len(seq)):\n            in_seq, out_seq = seq[:i], seq[i]\n            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n            out_seq = to_categorical([out_seq], num_classes = vocab_size)[0]\n            X1.append(photo)\n            X2.append(in_seq)\n            y.append(out_seq)\n    return array(X1), array(X2), array(y)","metadata":{"execution":{"iopub.status.busy":"2024-05-05T13:04:44.163495Z","iopub.execute_input":"2024-05-05T13:04:44.164219Z","iopub.status.idle":"2024-05-05T13:04:44.174828Z","shell.execute_reply.started":"2024-05-05T13:04:44.164186Z","shell.execute_reply":"2024-05-05T13:04:44.173858Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def define_model(vocab_size, max_length):\n    input1 = Input(shape=(4096,))\n    fe1 = Dropout(0.5)(input1)\n    fe2 = Dense(256, activation='relu')(fe1)\n    input2 = Input(shape=(max_length,))\n    se1 = Embedding(vocab_size, 256, mask_zero=True)(input2)\n    se2 = Dropout(0.5)(se1)\n    se3 = LSTM(256)(se2)\n    decoder1 = concatenate([fe2, se3])\n    decoder2 = Dense(256, activation = 'relu')(decoder1)\n    outputs = Dense(vocab_size, activation = 'softmax')(decoder2)\n    model = Model(inputs=[input1, input2], outputs=outputs)\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n    print(model.summary())\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-05T13:15:53.758378Z","iopub.execute_input":"2024-05-05T13:15:53.758741Z","iopub.status.idle":"2024-05-05T13:15:53.766189Z","shell.execute_reply.started":"2024-05-05T13:15:53.758712Z","shell.execute_reply":"2024-05-05T13:15:53.76525Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def data_generator(descriptions, photos, tokenizer, max_length):\n    while 1:\n        for key, desc_list in descriptions.items():\n            photo = photos[key][0]\n            in_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n            yield [[in_img, in_seq], out_word]","metadata":{"execution":{"iopub.status.busy":"2024-05-05T13:16:08.118263Z","iopub.execute_input":"2024-05-05T13:16:08.118623Z","iopub.status.idle":"2024-05-05T13:16:08.124478Z","shell.execute_reply.started":"2024-05-05T13:16:08.118593Z","shell.execute_reply":"2024-05-05T13:16:08.123342Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = create_tokenizer(train_descriptions)\nvocab_size = len(tokenizer.word_index) + 1\n\n# Maximum number of words in a line or sentence\nmax_length = max_length_function(train_descriptions)\n\n# Defining the final Model\nmodel = define_model(vocab_size, max_length)\n\n# train the model, run epochs manually and save after each epoch\nepochs = 2\nsteps = len(train_descriptions)\nfor i in range(epochs):\n    generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n    model.fit(generator, epochs=5, steps_per_epoch=steps, verbose=1)\n    model.save(directory + 'model_final_' + str(i) + '.h5')","metadata":{"execution":{"iopub.status.busy":"2024-05-05T13:16:36.47804Z","iopub.execute_input":"2024-05-05T13:16:36.478746Z","iopub.status.idle":"2024-05-05T13:16:36.539624Z","shell.execute_reply.started":"2024-05-05T13:16:36.478714Z","shell.execute_reply":"2024-05-05T13:16:36.538412Z"},"trusted":true},"outputs":[],"execution_count":null}]}