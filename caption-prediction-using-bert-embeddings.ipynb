{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8358531,"sourceType":"datasetVersion","datasetId":4967181},{"sourceId":8373203,"sourceType":"datasetVersion","datasetId":4978110},{"sourceId":8385552,"sourceType":"datasetVersion","datasetId":4987348},{"sourceId":8387140,"sourceType":"datasetVersion","datasetId":4988421},{"sourceId":8392890,"sourceType":"datasetVersion","datasetId":4992650},{"sourceId":8393545,"sourceType":"datasetVersion","datasetId":4993143},{"sourceId":8394484,"sourceType":"datasetVersion","datasetId":4993797},{"sourceId":8394770,"sourceType":"datasetVersion","datasetId":4994009},{"sourceId":8397591,"sourceType":"datasetVersion","datasetId":4995943},{"sourceId":8400887,"sourceType":"datasetVersion","datasetId":4998465},{"sourceId":8400908,"sourceType":"datasetVersion","datasetId":4998480},{"sourceId":8401022,"sourceType":"datasetVersion","datasetId":4998573}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nimport numpy as np\nfrom numpy import array\nimport pandas as pd\nimport cv2\nfrom glob import glob\nimport PIL\nimport time\nfrom tqdm import tqdm\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T12:40:42.234562Z","iopub.execute_input":"2024-05-13T12:40:42.235078Z","iopub.status.idle":"2024-05-13T12:40:42.242433Z","shell.execute_reply.started":"2024-05-13T12:40:42.235050Z","shell.execute_reply":"2024-05-13T12:40:42.241355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = \"/kaggle/input/images-new/images/images_normalized/\"\nimages = glob(image_path + \"*.png\")\nlen(images)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:40:42.656478Z","iopub.execute_input":"2024-05-13T12:40:42.656842Z","iopub.status.idle":"2024-05-13T12:40:42.689937Z","shell.execute_reply.started":"2024-05-13T12:40:42.656814Z","shell.execute_reply":"2024-05-13T12:40:42.689128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n# Read in the projections data\nprojections = pd.read_csv('/kaggle/input/images-new/indiana_projections.csv')\n\n# Read in the reports data\nreports = pd.read_csv('/kaggle/input/new-datasetcsv/indiana_reports.csv')\n\n# Define the path to the images folder\nimages_folder = '/kaggle/input/images-new/images/images_normalized'\n\n# Merge the projections and reports data on the UID column\nreports = pd.merge(projections, reports, on='uid')\n\n# Create a dictionary of image filenames and their corresponding captions\ndata = {}\nfor i in range(len(reports)):\n    filename = reports.loc[i, 'filename']\n    caption = reports.loc[i, 'impression']\n    if filename not in data:\n        data[filename] = []\n    if isinstance(caption, str) and re.match(r'^\\d+\\.', caption):\n        data[filename].append(caption.split('. ')[1])\n    else:\n        if data[filename]:\n            data[filename][-1] += \" \" + caption\n        else:\n            data[filename].append(caption)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:40:48.557515Z","iopub.execute_input":"2024-05-13T12:40:48.558475Z","iopub.status.idle":"2024-05-13T12:40:48.901136Z","shell.execute_reply.started":"2024-05-13T12:40:48.558439Z","shell.execute_reply":"2024-05-13T12:40:48.900158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanse_data(data):\n    dict_2 = dict()\n    for key, value in data.items():\n        for i in range(len(value)):\n            lines = \"\"\n            line1 = value[i]\n            if isinstance(line1, str):\n                for j in line1.split():\n                    if len(j) < 2:\n                        continue\n                    j = j.lower()\n                    lines += j + \" \"\n                if key not in dict_2:\n                    dict_2[key] = list()\n                dict_2[key].append(lines)\n    return dict_2\n\ndata2 = cleanse_data(data)\nprint(len(data2))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:40:54.969828Z","iopub.execute_input":"2024-05-13T12:40:54.970642Z","iopub.status.idle":"2024-05-13T12:40:55.027238Z","shell.execute_reply.started":"2024-05-13T12:40:54.970610Z","shell.execute_reply":"2024-05-13T12:40:55.026319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vocabulary(data2):\n    all_desc = set()\n    for key in data2.keys():\n        [all_desc.update(d.split()) for d in data2[key]]\n    return all_desc\n\n# summarize vocabulary\nvocabulary_data = vocabulary(data2)\nprint(len(vocabulary_data))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:40:57.463157Z","iopub.execute_input":"2024-05-13T12:40:57.464170Z","iopub.status.idle":"2024-05-13T12:40:57.484822Z","shell.execute_reply.started":"2024-05-13T12:40:57.464135Z","shell.execute_reply":"2024-05-13T12:40:57.484047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_dict(data2, filename):\n    lines = list()\n    for key, value in data2.items():\n        for desc in value:\n            lines.append(key + ' ' + desc)\n    data = '\\n'.join(lines)\n    file = open(filename, 'w')\n    file.write(data)\n    file.close()\nprint(data2)\nsave_dict(data2, 'captions1.txt')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:19:48.143107Z","iopub.execute_input":"2024-05-13T13:19:48.143985Z","iopub.status.idle":"2024-05-13T13:19:48.175430Z","shell.execute_reply.started":"2024-05-13T13:19:48.143951Z","shell.execute_reply":"2024-05-13T13:19:48.174471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D\nfrom keras.layers import Flatten, Concatenate, Dropout, BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.applications.densenet import DenseNet121\nfrom keras.applications.densenet import preprocess_input\nimport numpy as np\nimport pickle\nimport os\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import load_img, img_to_array\n\ndef chexnet(input_shape=(224,224,3), weights_path=None):\n    input_layer = Input(shape=input_shape, name='input_1')\n    densenet = DenseNet121(weights=None, include_top=False, input_tensor=input_layer)\n\n    if weights_path is not None:\n        densenet.load_weights(weights_path, by_name=True)\n\n    x = densenet.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(14, activation='sigmoid', kernel_regularizer=l2(0.0001))(x)\n    model = Model(inputs=densenet.input, outputs=predictions)\n\n    return model\n\n# Define the input shape of the model\ninput_shape = (224, 224, 3)\n\n# Load the pre-trained CheXNet model\nbase_model = chexnet(input_shape=input_shape, weights_path='/kaggle/input/weights/brucechou1983_CheXNet_Keras_0.3.0_weights.h5')\n\n# Function to encode a given image into a vector\ndef encode(image):\n    image = preprocess_input(image) # preprocess the image\n    fea_vec = base_model.predict(image) # Get the encoding vector for the image\n    fea_vec = np.reshape(fea_vec, fea_vec.shape[1]) # reshape\n    return fea_vec\n\n# Define the directory containing the chest X-ray images\nimg_dir = '/kaggle/input/images-new/images/images_normalized'\n\n# Get a list of all the image filenames in the directory\nimg_list = os.listdir(img_dir)\n\nencoding = {}\n\nfor img_filename in tqdm(img_list):\n    # Load the image from the file\n    img_path = os.path.join(img_dir, img_filename)\n    img = load_img(img_path, target_size=input_shape[:2])\n    x = img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    # Encode the image and store the encoding vector\n    encoding[img_filename] = encode(x)\n\n# Save the encoding vectors as a pickle file\nwith open(\"encodings.pkl\", \"wb\") as f:\n    pickle.dump(encoding, f)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:15:08.875717Z","iopub.execute_input":"2024-05-13T10:15:08.876408Z","iopub.status.idle":"2024-05-13T10:15:12.596488Z","shell.execute_reply.started":"2024-05-13T10:15:08.876378Z","shell.execute_reply":"2024-05-13T10:15:12.5951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_captions = []\n\nfor key, val in data2.items():\n    for cap in val:\n        all_captions.append(cap)\n        \nlen(all_captions)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:41:13.023493Z","iopub.execute_input":"2024-05-13T12:41:13.024142Z","iopub.status.idle":"2024-05-13T12:41:13.033609Z","shell.execute_reply.started":"2024-05-13T12:41:13.024110Z","shell.execute_reply":"2024-05-13T12:41:13.032647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nimport pickle\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(all_captions)\nvocab_size = len(tokenizer.word_index) + 1\n\n# text to sequence\ndtexts = tokenizer.texts_to_sequences(all_captions)\nwith open(\"/kaggle/working/index_word.pkl\", 'wb') as fp:\n    pickle.dump(tokenizer, fp)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:53:10.814016Z","iopub.execute_input":"2024-05-13T12:53:10.814983Z","iopub.status.idle":"2024-05-13T12:53:11.050804Z","shell.execute_reply.started":"2024-05-13T12:53:10.814944Z","shell.execute_reply":"2024-05-13T12:53:11.049959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dtexts)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:53:13.366743Z","iopub.execute_input":"2024-05-13T12:53:13.367494Z","iopub.status.idle":"2024-05-13T12:53:13.373407Z","shell.execute_reply.started":"2024-05-13T12:53:13.367456Z","shell.execute_reply":"2024-05-13T12:53:13.372357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:41:32.665636Z","iopub.execute_input":"2024-05-13T12:41:32.665995Z","iopub.status.idle":"2024-05-13T12:41:32.672330Z","shell.execute_reply.started":"2024-05-13T12:41:32.665969Z","shell.execute_reply":"2024-05-13T12:41:32.671214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = max(len(caption.split()) for caption in all_captions)\nmax_length","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:41:34.830336Z","iopub.execute_input":"2024-05-13T12:41:34.830686Z","iopub.status.idle":"2024-05-13T12:41:34.842068Z","shell.execute_reply.started":"2024-05-13T12:41:34.830657Z","shell.execute_reply":"2024-05-13T12:41:34.841113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prop_test, prop_val = 0.2, 0.2\n\nN = len(dtexts)\nNtest, Nval = int(N*prop_test), int(N*prop_val)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:41:39.040484Z","iopub.execute_input":"2024-05-13T12:41:39.040893Z","iopub.status.idle":"2024-05-13T12:41:39.046178Z","shell.execute_reply.started":"2024-05-13T12:41:39.040857Z","shell.execute_reply":"2024-05-13T12:41:39.045123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join('/kaggle/input/encodingssss', 'encodings.pkl'), 'rb') as f:\n    features = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:22.944628Z","iopub.execute_input":"2024-05-13T12:43:22.945007Z","iopub.status.idle":"2024-05-13T12:43:22.986423Z","shell.execute_reply.started":"2024-05-13T12:43:22.944977Z","shell.execute_reply":"2024-05-13T12:43:22.985638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(features)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:31.139648Z","iopub.execute_input":"2024-05-13T12:43:31.140627Z","iopub.status.idle":"2024-05-13T12:43:31.146862Z","shell.execute_reply.started":"2024-05-13T12:43:31.140591Z","shell.execute_reply":"2024-05-13T12:43:31.145660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dimages = []\nfor key,val in features.items():\n    dimages.append(val)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:33.299698Z","iopub.execute_input":"2024-05-13T12:43:33.300042Z","iopub.status.idle":"2024-05-13T12:43:33.306741Z","shell.execute_reply.started":"2024-05-13T12:43:33.300017Z","shell.execute_reply":"2024-05-13T12:43:33.305672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_test_val_train(dtexts,Ntest,Nval):\n    return(dtexts[:Ntest],\n           dtexts[Ntest:Ntest+Nval],\n           dtexts[Ntest+Nval:])\n\ndt_test,  dt_val, dt_train   = split_test_val_train(dtexts,Ntest,Nval)\ndi_test,  di_val, di_train   = split_test_val_train(dimages,Ntest,Nval)\n\nmaxlen = np.max([len(text) for text in dtexts])\nprint(maxlen)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:35.811359Z","iopub.execute_input":"2024-05-13T12:43:35.812231Z","iopub.status.idle":"2024-05-13T12:43:35.821496Z","shell.execute_reply.started":"2024-05-13T12:43:35.812199Z","shell.execute_reply":"2024-05-13T12:43:35.820351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(dtexts,dimages):\n    N = len(dtexts)\n    print(\"# captions/images = {}\".format(N))\n\n    assert(N==len(dimages)) # using assert to make sure that length of images and captions are always similar\n    Xtext, Ximage, ytext = [],[],[]\n    for text,image in zip(dtexts,dimages):\n        # zip() is used to create a tuple of iteratable items\n        for i in range(1,len(text)):\n            in_text, out_text = text[:i], text[i]\n            in_text = pad_sequences([in_text],maxlen=maxlen).flatten()# using pad sequence to make the length of all captions equal\n            out_text = to_categorical(out_text,num_classes = vocab_size) # using to_categorical to\n\n\n            Xtext.append(in_text)\n            Ximage.append(image)\n            ytext.append(out_text)\n\n    Xtext  = np.array(Xtext)\n    Ximage = np.array(Ximage)\n    ytext  = np.array(ytext)\n    print(\" {} {} {}\".format(Xtext.shape,Ximage.shape,ytext.shape))\n    return(Xtext,Ximage,ytext)\n\n\nXtext_train, Ximage_train, ytext_train = preprocessing(dt_train[:4000],di_train[:4000])\nXtext_val,   Ximage_val,   ytext_val   = preprocessing(dt_val[:450],di_val[:450])\n\nprint(Ximage_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:38.153999Z","iopub.execute_input":"2024-05-13T12:43:38.154435Z","iopub.status.idle":"2024-05-13T12:43:40.492212Z","shell.execute_reply.started":"2024-05-13T12:43:38.154399Z","shell.execute_reply":"2024-05-13T12:43:40.491239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ximage_train_reshaped = Ximage_train.reshape(31404, 14)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:45.926686Z","iopub.execute_input":"2024-05-13T12:43:45.927394Z","iopub.status.idle":"2024-05-13T12:43:45.931730Z","shell.execute_reply.started":"2024-05-13T12:43:45.927361Z","shell.execute_reply":"2024-05-13T12:43:45.930618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ximage_train_reshaped.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:48.602924Z","iopub.execute_input":"2024-05-13T12:43:48.603722Z","iopub.status.idle":"2024-05-13T12:43:48.609500Z","shell.execute_reply.started":"2024-05-13T12:43:48.603692Z","shell.execute_reply":"2024-05-13T12:43:48.608519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ximage_val_reshaped = Ximage_val.reshape(3755, 14)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:50.708046Z","iopub.execute_input":"2024-05-13T12:43:50.708764Z","iopub.status.idle":"2024-05-13T12:43:50.712985Z","shell.execute_reply.started":"2024-05-13T12:43:50.708731Z","shell.execute_reply":"2024-05-13T12:43:50.711975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ximage_val_reshaped.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:43:56.071453Z","iopub.execute_input":"2024-05-13T12:43:56.071821Z","iopub.status.idle":"2024-05-13T12:43:56.078052Z","shell.execute_reply.started":"2024-05-13T12:43:56.071791Z","shell.execute_reply":"2024-05-13T12:43:56.077022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras.layers import Dropout\n\ndef build(vocab_size, maxlen, Ximage_shape):\n    global model\n    print(\"Vocabulary Size:\", vocab_size)\n    print(\"Max Length:\", maxlen)\n    print(\"Ximage Shape:\", Ximage_shape)\n\n\n    dim_embedding = 64\n\n    input_image = layers.Input(shape=(Ximage_shape,))\n    fimage = layers.Dense(256, activation='relu', name=\"ImageFeature\")(input_image)\n\n    input_txt = layers.Input(shape=(maxlen,))\n    ftxt = layers.Embedding(vocab_size, dim_embedding)(input_txt)\n    ftxt = layers.LSTM(256, name=\"CaptionFeature\", return_sequences=True)(ftxt)\n    se2 = Dropout(0.04)(ftxt)\n    ftxt = layers.LSTM(256, name=\"CaptionFeature2\")(se2)\n\n    decoder = layers.add([ftxt, fimage])\n    decoder = layers.Dense(256, activation='relu')(decoder)\n    output = layers.Dense(vocab_size, activation='softmax')(decoder)\n\n    model = models.Model(inputs=[input_image, input_txt], outputs=output)\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    print(model.summary())\n\n\n\nXimage_shape = 14\n\nbuild(vocab_size, maxlen, Ximage_shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:16:36.91389Z","iopub.execute_input":"2024-05-13T10:16:36.914255Z","iopub.status.idle":"2024-05-13T10:16:37.528295Z","shell.execute_reply.started":"2024-05-13T10:16:36.914226Z","shell.execute_reply":"2024-05-13T10:16:37.527381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import TensorBoard  # Use TensorFlow Keras imports\nfrom time import time\n\ndef train(model, Ximage_train_reshaped, Xtext_train, ytext_train, Ximage_val_reshaped, Xtext_val, ytext_val):\n    # Define the log directory for TensorBoard logs\n    log_dir = \"logs/{}\".format(int(time()))  # Convert time to an integer for the directory name\n\n    # Set up TensorBoard callback\n    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), write_graph=False)\n\n    # Training the model\n    history = model.fit(\n        [Ximage_train_reshaped, Xtext_train], ytext_train,\n        epochs=50, \n        verbose=2,\n        batch_size=32,\n        validation_data=([Ximage_val_reshaped, Xtext_val], ytext_val),\n        callbacks=[tensorboard]\n    )\n    return history\n\n# Example usage\n# Assuming 'model' and the data variables ('Ximage_train_reshaped', 'Xtext_train', etc.) are defined\n# train(model, Ximage_train_reshaped, Xtext_train, ytext_train, Ximage_val_reshaped, Xtext_val, ytext_val)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:18:43.032485Z","iopub.execute_input":"2024-05-13T10:18:43.032847Z","iopub.status.idle":"2024-05-13T10:18:43.040238Z","shell.execute_reply.started":"2024-05-13T10:18:43.032808Z","shell.execute_reply":"2024-05-13T10:18:43.039161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history= train(model, Ximage_train_reshaped, Xtext_train, ytext_train, Ximage_val_reshaped, Xtext_val, ytext_val)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:18:47.962042Z","iopub.execute_input":"2024-05-13T10:18:47.962746Z","iopub.status.idle":"2024-05-13T10:33:06.691688Z","shell.execute_reply.started":"2024-05-13T10:18:47.962718Z","shell.execute_reply":"2024-05-13T10:33:06.690702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/lstm-img-caption-1000-1.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:33:20.96072Z","iopub.execute_input":"2024-05-13T10:33:20.961631Z","iopub.status.idle":"2024-05-13T10:33:21.03576Z","shell.execute_reply.started":"2024-05-13T10:33:20.961595Z","shell.execute_reply":"2024-05-13T10:33:21.034633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom nltk.translate.bleu_score import sentence_bleu\n\nnpic = 5\nnpix = 224\ntarget_size = (npix,npix,3)\n#index_word = dict([(index,word) for word, index in tokenizer.word_index.items()])\n\n# nb_words = 6000\n# tokenizer = Tokenizer(nb_words=nb_words)\n# with open('index_word.json', 'r') as file:\n#     index_word = json.load(file)\ndef idx_to_word(integer, tokenizer):\n    for word, index in tokenizer.word_index.items():\n        if index == integer:\n            return word\n    return None\n\nmodel = load_model('/kaggle/input/trained-model/lstm-img-caption-1000-1(1).h5')\ndef predict_caption(image):\n    '''\n    image.shape = (1,4462)\n    '''\n\n    in_text = 'startseq'\n\n    for iword in range(maxlen):\n        sequence = tokenizer.texts_to_sequences([in_text])[0]\n        sequence = pad_sequences([sequence],maxlen)\n        #print(\"Len: \",[sequence],maxlen,image,model)\n        yhat = model.predict([image,sequence],verbose=0)\n        #print(yhat)\n        yhat = np.argmax(yhat)\n        word = idx_to_word(yhat, tokenizer)\n        in_text += \" \" + word\n        if word == \"endseq\":\n            break\n    return(in_text)\n\ncount = 1\n\ntest = dimages[12]\nfor i in range(len(test)):\n    ## captions\n    image_feature = dimages[i]\n    image_feature = image_feature.reshape(14)\n    new_f = image_feature.reshape(1,len(image_feature))\n    #print(new_f.shape)\n    caption = dtexts[i]\n    pred_caption = predict_caption(new_f)\n    print(pred_caption)\n    bleu1_score = sentence_bleu([caption],pred_caption, weights=(1, 0, 0, 0))\n    print(\"BLEU-1 Score:\", bleu1_score)\n    bleu2_score = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0))\n    print(\"BLEU-2 Score:\", bleu2_score)\n    bleu3_score = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0))\n    print(\"BLEU-3 Score:\", bleu3_score)\n    bleu = sentence_bleu([caption],pred_caption)\n    print(bleu)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:23:38.458862Z","iopub.execute_input":"2024-05-13T13:23:38.459640Z","iopub.status.idle":"2024-05-13T13:25:33.505547Z","shell.execute_reply.started":"2024-05-13T13:23:38.459605Z","shell.execute_reply":"2024-05-13T13:25:33.504507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the model\nmodel = load_model('/kaggle/input/model123/model_3.h5')\n\n# Print the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T13:07:45.677316Z","iopub.execute_input":"2024-05-13T13:07:45.678345Z","iopub.status.idle":"2024-05-13T13:07:45.957478Z","shell.execute_reply.started":"2024-05-13T13:07:45.678282Z","shell.execute_reply":"2024-05-13T13:07:45.955884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(['training', 'validation'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:33:24.838706Z","iopub.execute_input":"2024-05-13T10:33:24.839096Z","iopub.status.idle":"2024-05-13T10:33:25.146375Z","shell.execute_reply.started":"2024-05-13T10:33:24.839066Z","shell.execute_reply":"2024-05-13T10:33:25.1455Z"},"trusted":true},"execution_count":null,"outputs":[]}]}